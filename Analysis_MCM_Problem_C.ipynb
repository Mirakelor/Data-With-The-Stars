{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2026 MCM Problem C: Analysis & Solution Pipeline\n",
    "\n",
    "## 1. Introduction & Overview\n",
    "This notebook documents the computational framework used to analyze the dynamics of the *Dancing with the Stars* voting system. Our approach integrates rigorous data preprocessing, Bayesian inverse optimization, and statistical modeling to reconstruct hidden fan voting patterns and evaluate their impact on competition outcomes.\n",
    "\n",
    "### Core Components:\n",
    "1.  **Data Ingestion**: Transforming raw season data into a standardized longitudinal format.\n",
    "2.  **Latent Variable Reconstruction**: Using MCMC to infer judging/fan weights from elimination outcomes.\n",
    "3.  **Statistical Inference**: Quantifying the impact of demographics, partnerships, and scores on survival.\n",
    "4.  **Policy Simulation**: Counterfactual analysis of alternative voting rules.\n",
    "\n",
    "---\n",
    "## 2. Data Loading and Preprocessing\n",
    "We begin by standardizing the heterogeneous weekly score data into a unified temporal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import rankdata\n",
    "import re\n",
    "from typing import Iterable, List, Optional, Tuple, Dict\n",
    "import statsmodels.api as sm\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- PLOTTING STYLE SETUP ---\n",
    "# Set a modern, clean theme for all plots\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False # For negative numbers\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "# --- DATA PREPROCESSING & STANDARDIZATION ---\n",
    "\n",
    "WEEK_SCORE_PATTERN = re.compile(r\"^week(\\d+)_judge(\\d+)_score$\")\n",
    "\n",
    "def load_raw_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load the raw dataset.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def parse_elimination_week(result_str: object) -> Optional[object]:\n",
    "    \"\"\"\n",
    "    Parses the elimination week from the result string.\n",
    "    Returns the week number (int) or 'Final' (str).\n",
    "    \"\"\"\n",
    "    if pd.isna(result_str):\n",
    "        return None\n",
    "    text = str(result_str)\n",
    "    match = re.search(r\"Eliminated Week (\\d+)\", text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    if \"Place\" in text:\n",
    "        return \"Final\"\n",
    "    return None\n",
    "\n",
    "def _week_numbers_from_columns(columns: Iterable[str]) -> List[int]:\n",
    "    \"\"\"Extracts all unique week numbers present in the column headers.\"\"\"\n",
    "    week_numbers = set()\n",
    "    for col in columns:\n",
    "        match = WEEK_SCORE_PATTERN.match(col)\n",
    "        if match:\n",
    "            week_numbers.add(int(match.group(1)))\n",
    "    return sorted(week_numbers)\n",
    "\n",
    "def _score_columns_for_week(columns: Iterable[str], week: int) -> List[str]:\n",
    "    \"\"\"Returns column names corresponding to a specific week.\"\"\"\n",
    "    prefix = f\"week{week}_\"\n",
    "    return [c for c in columns if c.startswith(prefix) and c.endswith(\"_score\")]\n",
    "\n",
    "def _sum_week_scores(row: pd.Series, score_cols: List[str]) -> Optional[float]:\n",
    "    \"\"\"Calculates the aggregate judge score for a given week.\"\"\"\n",
    "    if not score_cols:\n",
    "        return None\n",
    "    values = pd.to_numeric(row[score_cols], errors=\"coerce\")\n",
    "    if values.isna().all():\n",
    "        return None\n",
    "    return float(values.fillna(0).sum())\n",
    "\n",
    "def compute_weekly_scores(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms the raw wide-format data into a standard long-format temporal dataset.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Contains [Season, Week, Contestant, JudgeScore, EliminatedThisWeek, Result, Placement]\n",
    "    \"\"\"\n",
    "    week_numbers = _week_numbers_from_columns(df.columns)\n",
    "    records = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        contestant = row[\"celebrity_name\"]\n",
    "        season = row[\"season\"]\n",
    "        elim_week = parse_elimination_week(row[\"results\"])\n",
    "\n",
    "        for week in week_numbers:\n",
    "            score_cols = _score_columns_for_week(df.columns, week)\n",
    "            total_score = _sum_week_scores(row, score_cols)\n",
    "            \n",
    "            # Filter out weeks where the contestant did not compete\n",
    "            if total_score is None or total_score <= 0:\n",
    "                continue\n",
    "\n",
    "            records.append(\n",
    "                {\n",
    "                    \"Season\": int(season),\n",
    "                    \"Week\": int(week),\n",
    "                    \"Contestant\": contestant,\n",
    "                    \"JudgeScore\": total_score,\n",
    "                    \"EliminatedThisWeek\": (elim_week == week),\n",
    "                    \"Result\": row.get(\"results\", None),\n",
    "                    \"Placement\": row.get(\"placement\", None),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Execute Data Ingestion\n",
    "file_path = '2026_MCM_Problem_C_Data.csv'\n",
    "df = load_raw_data(file_path)\n",
    "df_weekly = compute_weekly_scores(df)\n",
    "\n",
    "print(f\"Data Loaded: {len(df_weekly)} weekly observations.\")\n",
    "print(f\"Temporal Range: Season {df_weekly['Season'].min()} to {df_weekly['Season'].max()}.\")\n",
    "display(df_weekly.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Numerical Implementation of Voting Rules\n",
    "\n",
    "We implement the historical voting regimes as algorithmic predicates for the simulation:\n",
    "\n",
    "**1. Traditional Rank-Based (Season 1-2)**\n",
    "*   **Metric**: Sum of Judge Rank and Fan Rank.\n",
    "*   **Elimination**: The contestant with the **highest rank sum** (worst performance) is eliminated.\n",
    "*   **Tie-Breaker**: The contestant with the worse Fan Rank is eliminated.\n",
    "\n",
    "**2. Percentage-Based (Season 3-27)**\n",
    "*   **Metric**: Judge Point Share (normalized) + Fan Vote Share.\n",
    "*   **Elimination**: The contestant with the **lowest total percentage** is eliminated.\n",
    "*   **Tie-Breaker**: The contestant with the lower Fan Vote Share is eliminated.\n",
    "\n",
    "**3. Rank-Based with \"Judge Save\" (Season 28-32)**\n",
    "*   **Metric**: Sum of Judge Rank and Fan Rank.\n",
    "*   **Elimination**: The \"Bottom Two\" are identified by the highest rank sums. Between these two, the judges vote to save oneâ€”in our model, this is simulated as eliminating the one with the **lower raw judge score**.\n",
    "</VSCode.Cell>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ranks(scores, ascending=False):\n",
    "    \"\"\"\n",
    "    Computes ordinal ranks for a score vector.\n",
    "    \"\"\"\n",
    "    if not ascending:\n",
    "        return rankdata([-s for s in scores], method='min')\n",
    "    return rankdata(scores, method='min')\n",
    "\n",
    "def calculate_rank_elimination(judge_scores, fan_ranks, season_num):\n",
    "    \"\"\"\n",
    "    Determines the eliminated contestant under the Rank-Based Rule.\n",
    "    \n",
    "    Logic:\n",
    "        - Seasons < 28: Simple Worst Total Rank (Sum).\n",
    "        - Seasons >= 28: \"Judge Save\" logic. Bottom Two by Rank Sum, then \n",
    "                         eliminate the one with the lower judge score.\n",
    "    \"\"\"\n",
    "    j_ranks = calculate_ranks(judge_scores)\n",
    "    total_ranks = j_ranks + fan_ranks\n",
    "    \n",
    "    if season_num >= 28:\n",
    "        # Judge Save Logic: Find Bottom Two\n",
    "        combined = []\n",
    "        for i in range(len(total_ranks)):\n",
    "            combined.append({\n",
    "                'total_rank': total_ranks[i],\n",
    "                'judge_score': judge_scores[i],\n",
    "                'index': i\n",
    "            })\n",
    "        # Sort by total rank sum descending (worst first)\n",
    "        combined.sort(key=lambda x: x['total_rank'], reverse=True)\n",
    "        \n",
    "        # Bottom Two identify\n",
    "        bottom_two = combined[:2]\n",
    "        if len(bottom_two) < 2:\n",
    "            return bottom_two[0]['index']\n",
    "            \n",
    "        # Eliminate the one with the LOWER judge score among bottom two\n",
    "        if bottom_two[0]['judge_score'] < bottom_two[1]['judge_score']:\n",
    "            return bottom_two[0]['index']\n",
    "        else:\n",
    "            return bottom_two[1]['index']\n",
    "    else:\n",
    "        # Traditional Logic: Simple Highest Rank Sum\n",
    "        combined = []\n",
    "        for i in range(len(total_ranks)):\n",
    "            combined.append((total_ranks[i], fan_ranks[i], i))\n",
    "        # Sort descending: Highest Total rank = eliminated\n",
    "        # Tie-breaker: worse fan rank\n",
    "        combined.sort(key=lambda x: (x[0], x[1]), reverse=True)\n",
    "        return combined[0][2]\n",
    "\n",
    "def calculate_percent_elimination(judge_scores, fan_percents):\n",
    "    \"\"\"\n",
    "    Determines the eliminated contestant under the Percentage-Based Rule (S3-27).\n",
    "    Logic: Lowest Total Percentage (Judge % + Fan %) is eliminated.\n",
    "    \"\"\"\n",
    "    total_judge = sum(judge_scores)\n",
    "    if total_judge == 0: \n",
    "        j_percents = np.zeros(len(judge_scores))\n",
    "    else:\n",
    "        j_percents = np.array(judge_scores) / total_judge\n",
    "        \n",
    "    total_score = j_percents + fan_percents\n",
    "    \n",
    "    # Sort Ascending: Lowest Total Score = Eliminated\n",
    "    combined = []\n",
    "    for i in range(len(total_score)):\n",
    "        combined.append((total_score[i], fan_percents[i], i))\n",
    "    \n",
    "    combined.sort(key=lambda x: (x[0], x[1]))\n",
    "    return combined[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stochastic Inverse Optimization via Bayesian Inference\n",
    "\n",
    "We employ a **Bayesian Markov Chain Monte Carlo (MCMC)** approach to estimate the posterior distribution of latent fan support, conditioned on observed elimination outcomes.\n",
    "\n",
    "**Methodology**\n",
    "We model the unknown fan support vector $\\mathbf{P}_F$ with a Dirichlet prior:\n",
    "$$ \\mathbf{P}_F \\sim \\text{Dirichlet}(\\boldsymbol{\\alpha}) $$\n",
    "\n",
    "where $\\boldsymbol{\\alpha}$ encodes prior belief (centered around equal popularity, with inertia from previous weeks).\n",
    "\n",
    "**Algorithm**\n",
    "1. **Prior Construction**: Define $\\boldsymbol{\\alpha}_t$ from the posterior mean of week $t-1$.\n",
    "2. **Sampling**: Draw **$N=50{,}000$** samples from $\\text{Dirichlet}(\\boldsymbol{\\alpha}_t)$.\n",
    "3. **Validation**: Accept samples whose simulated elimination matches the observed result $E_{obs}$.\n",
    "4. **Posterior Estimation**: Use accepted samples to estimate fan support and uncertainty.\n",
    "\n",
    "**Optimization Note**: Increasing $N$ reduces Monte Carlo error at rate $\\propto 1/\\sqrt{N}$ and improves stability in rank-based seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voting_mode(season_num: int) -> str:\n",
    "    \"\"\"Returns 'rank' or 'percent' based on historical rules.\"\"\"\n",
    "    if season_num <= 2 or season_num >= 28:\n",
    "        return 'rank'\n",
    "    return 'percent'\n",
    "\n",
    "def simulate_fan_votes(season_num: int, week_num: int, num_samples: int = 50000, \n",
    "                       prior_support: dict = None, inertia_weight: float = 100.0,\n",
    "                       override_judge_scores: np.ndarray = None):\n",
    "    \"\"\"\n",
    "    Performs Bayesian inference to estimate fan votes consistent with the observed elimination.\n",
    "\n",
    "    Parameters:\n",
    "        season_num (int): Target season.\n",
    "        week_num (int): Target week.\n",
    "        num_samples (int): Number of Monte Carlo iterations (default: 50,000).\n",
    "        prior_support (dict): Posterior means from previous week (inertia).\n",
    "        inertia_weight (float): Strength of the temporal smoothing/prior.\n",
    "        override_judge_scores (np.array): Optional array to replace actual judge scores (for robustness testing).\n",
    "\n",
    "    Returns:\n",
    "        samples (np.array): Matrix of accepted fan vote vectors.\n",
    "        names (np.array): Array of contestant names.\n",
    "        mode (str): Voting mechanism used ('rank' or 'percent').\n",
    "    \"\"\"\n",
    "    subset = df_weekly[(df_weekly['Season'] == season_num) & (df_weekly['Week'] == week_num)].copy()\n",
    "    if subset.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    # Detect observed elimination\n",
    "    eliminated_rows = subset[subset['EliminatedThisWeek'] == True]\n",
    "    has_elimination = not eliminated_rows.empty\n",
    "\n",
    "    contestants = subset['Contestant'].values\n",
    "    \n",
    "    # Use override scores if provided (for robustness testing), else use actuals\n",
    "    if override_judge_scores is not None:\n",
    "        judge_scores = override_judge_scores\n",
    "    else:\n",
    "        judge_scores = subset['JudgeScore'].values\n",
    "\n",
    "    # Map eliminated names to indices\n",
    "    elim_indices = []\n",
    "    if has_elimination:\n",
    "        for elim_name in eliminated_rows['Contestant'].values:\n",
    "            idx = np.where(contestants == elim_name)[0]\n",
    "            if len(idx) > 0:\n",
    "                elim_indices.append(idx[0])\n",
    "\n",
    "    num_c = len(contestants)\n",
    "    valid_fan_votes = []\n",
    "    mode = get_voting_mode(season_num)\n",
    "\n",
    "    # Informative priors (hyperparameters)\n",
    "    base_alpha = 5.0\n",
    "    \n",
    "    alphas = []\n",
    "    for name in contestants:\n",
    "        if prior_support and name in prior_support:\n",
    "            prev = prior_support[name]\n",
    "            if mode == 'rank' and prev >= 1.0:\n",
    "                weight = (num_c + 1 - prev)\n",
    "                alphas.append(base_alpha + (5.0 * weight)) # Scale rank inertia differently\n",
    "            else:\n",
    "                alphas.append(base_alpha + (inertia_weight * prev))\n",
    "        else:\n",
    "            alphas.append(base_alpha + (inertia_weight * (1.0 / num_c)))\n",
    "\n",
    "    alphas = np.array(alphas)\n",
    "\n",
    "    # Monte Carlo sampling\n",
    "    try:\n",
    "        raw_samples = np.random.dirichlet(alphas, num_samples)\n",
    "    except Exception:\n",
    "        raw_samples = np.random.dirichlet(np.ones(num_c) * base_alpha, num_samples)\n",
    "\n",
    "    for fan_pcts in raw_samples:\n",
    "        if mode == 'rank':\n",
    "            fan_ranks = rankdata([-p for p in fan_pcts], method='min')\n",
    "            if has_elimination:\n",
    "                loser_idx = calculate_rank_elimination(judge_scores, fan_ranks, season_num)\n",
    "                if loser_idx in elim_indices:\n",
    "                    valid_fan_votes.append(fan_ranks)\n",
    "            else:\n",
    "                valid_fan_votes.append(fan_ranks)\n",
    "        else:\n",
    "            if has_elimination:\n",
    "                loser_idx = calculate_percent_elimination(judge_scores, fan_pcts)\n",
    "                if loser_idx in elim_indices:\n",
    "                    valid_fan_votes.append(fan_pcts)\n",
    "            else:\n",
    "                valid_fan_votes.append(fan_pcts)\n",
    "\n",
    "    if len(valid_fan_votes) == 0:\n",
    "        return None, contestants, mode\n",
    "\n",
    "    return np.array(valid_fan_votes), contestants, mode\n",
    "\n",
    "print(\"Bayesian Inference Model initialized (Updated with Season-aware Elimination Rules).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Global Parameter Estimation & Historical Reconstruction\n",
    "\n",
    "Having validated the Bayesian inference engine on singular cases, we now scale the process to reconstruction of the latent fan support trajectories for the entire historical dataset.\n",
    "\n",
    "**Procedure:**\n",
    "*   **Sequential Bayesian Updating**: For each season, we initialize a flat prior. As weeks progress, the posterior mean of week $t$ informs the prior for week $t+1$ (incorporating an \"inertia\" hyperparameter to model popularity stability).\n",
    "*   **Output generation**: This yields a longitudinal dataset of `Est_Fan_Support` and `Est_Fan_Uncertainty` for every contestant-week tuple.\n",
    "\n",
    "*Computation Note: This involves executing the MCMC sampling routine for every elimination event across all seasons.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Historical Reconstruction Loop (Sequential) ---\n",
    "\n",
    "full_history_stats = []\n",
    "seasons = sorted(df_weekly['Season'].unique())\n",
    "\n",
    "print(f\"Starting reconstruction for {len(seasons)} seasons...\")\n",
    "\n",
    "# SKIP SIMULATION IF FILE EXISTS TO SAVE TIME\n",
    "import os\n",
    "if os.path.exists('estimated_fan_votes.csv'):\n",
    "    print(\"Found existing 'estimated_fan_votes.csv'. Loading data...\")\n",
    "    df_estimated_full = pd.read_csv('estimated_fan_votes.csv')\n",
    "else:\n",
    "    print(\"No existing data found. Running simulation (this may take a long time)...\")\n",
    "    for s in seasons:\n",
    "        weeks = sorted(df_weekly[df_weekly['Season'] == s]['Week'].unique())\n",
    "        current_season_priors = {}\n",
    "\n",
    "        for w in weeks:\n",
    "            # Increased samples to 50,000 for higher-fidelity reconstruction\n",
    "            feasible, names, mode = simulate_fan_votes(s, w, num_samples=50000, prior_support=current_season_priors)\n",
    "\n",
    "            if feasible is not None and len(feasible) > 0:\n",
    "                means = feasible.mean(axis=0)\n",
    "                stds = feasible.std(axis=0)\n",
    "\n",
    "                for i, name in enumerate(names):\n",
    "                    current_season_priors[name] = means[i]\n",
    "\n",
    "                    full_history_stats.append({\n",
    "                        'Season': s,\n",
    "                        'Week': w,\n",
    "                        'Contestant': name,\n",
    "                        'Judge_Score': df_weekly[(df_weekly['Season'] == s) & (df_weekly['Week'] == w) & (df_weekly['Contestant'] == name)]['JudgeScore'].values[0],\n",
    "                        'Est_Fan_Support': means[i],\n",
    "                        'Est_Fan_Uncertainty': stds[i],\n",
    "                        'Voting_Mode': mode\n",
    "                    })\n",
    "\n",
    "    # Save Results\n",
    "    if full_history_stats:\n",
    "        df_estimated_full = pd.DataFrame(full_history_stats)\n",
    "        df_estimated_full.to_csv('estimated_fan_votes.csv', index=False)\n",
    "        print(f\"Completed. Generated {len(df_estimated_full)} records.\")\n",
    "        print(\"Saved to 'estimated_fan_votes.csv'.\")\n",
    "\n",
    "# Merge for analysis\n",
    "df_full_analysis = pd.merge(df_weekly, df_estimated_full, on=['Season', 'Week', 'Contestant'], how='left')\n",
    "display(df_estimated_full.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Diagnostics and Validation\n",
    "\n",
    "We assess the reliability of the reconstructed latent variables through two metrics:\n",
    "\n",
    "### 6.1 Posterior Variance Analysis\n",
    "The standard deviation of the posterior distribution (`Est_Fan_Uncertainty`) quantifies the **identifiability** of the fan vote.\n",
    "*   **High Variance**: Indicates the solution space is broad; multiple fan vote configurations could explain the observed elimination (low judges' signal-to-noise ratio).\n",
    "*   **Low Variance**: Indicates the elimination constraint is tight; specific fan vote patterns are required to satisfy the outcome.\n",
    "\n",
    "### 6.2 Predictive Alignment (Rank Correlation)\n",
    "We evaluate the external validity by correlating the estimated mean fan support with the final season placement. A strong monotonic relationship (Spearman's $\\rho$) suggests the model essentially captures the \"true\" latent popularity driving long-term survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Diagnostics: Uncertainty & Validity ---\n",
    "\n",
    "# Load data if not present\n",
    "if 'df_estimated_full' not in locals():\n",
    "    df_estimated_full = pd.read_csv('estimated_fan_votes.csv')\n",
    "\n",
    "# --- ADDED VERIFICATION CODE START ---\n",
    "# Calculation of Model Fidelity/Consistency Rate\n",
    "print(\"--- Model Consistency Verification ---\")\n",
    "\n",
    "# 1. Identify all weeks in history where an elimination actually occurred\n",
    "# We group by Season/Week to count unique elimination events\n",
    "ground_truth_eliminations = df_weekly[df_weekly['EliminatedThisWeek'] == True][['Season', 'Week']].drop_duplicates()\n",
    "total_events = len(ground_truth_eliminations)\n",
    "\n",
    "# 2. Identify weeks where the model successfully found a feasible solution\n",
    "# (If the solver failed to find a valid vote distribution, those weeks are missing from df_estimated_full)\n",
    "reconstructed_weeks = df_estimated_full[['Season', 'Week']].drop_duplicates()\n",
    "\n",
    "# 3. Calculate Intersection (Successes)\n",
    "# We perform an inner join to see which elimination weeks have a corresponding reconstruction\n",
    "matches = pd.merge(ground_truth_eliminations, reconstructed_weeks, on=['Season', 'Week'], how='inner')\n",
    "successful_events = len(matches)\n",
    "\n",
    "consistency_rate = successful_events / total_events if total_events > 0 else 0\n",
    "\n",
    "print(f\"Total Elimination Events: {total_events}\")\n",
    "print(f\"Successfully Reconstructed Events: {successful_events}\")\n",
    "print(f\"Model Consistency (Feasibility Rate): {consistency_rate:.1%}\")\n",
    "# --- ADDED VERIFICATION CODE END ---\n",
    "\n",
    "# 1. Posterior Uncertainty Analysis\n",
    "# Examine the standard deviation of posterior distributions across voting modes.\n",
    "diag_data = df_estimated_full[['Season', 'Week', 'Est_Fan_Uncertainty', 'Voting_Mode']].copy()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.lineplot(data=diag_data, x='Season', y='Est_Fan_Uncertainty', hue='Voting_Mode', \n",
    "             style='Voting_Mode', markers=True, dashes=False, palette={'rank': '#2980b9', 'percent': '#d35400'})\n",
    "\n",
    "plt.title('Model Uncertainty Trends Across Seasons', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Posterior Standard Deviation\\n(Lower = Higher Confidence)')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. External Validity Check (Rank Correlation)\n",
    "# Correlate estimated fan support with final competition placement.\n",
    "# Validating assumption: Higher fan support should correlate with better (lower) placement.\n",
    "\n",
    "rank_data = df_full_analysis[(df_full_analysis['Voting_Mode'] == 'rank') & (df_full_analysis['Est_Fan_Support'].notna())]\n",
    "pct_data = df_full_analysis[(df_full_analysis['Voting_Mode'] == 'percent') & (df_full_analysis['Est_Fan_Support'].notna())]\n",
    "\n",
    "print(\"--- Predictive Validity (Spearman Correlation) ---\")\n",
    "metrics = []\n",
    "\n",
    "if not rank_data.empty:\n",
    "    rho_rank = rank_data[['Est_Fan_Support', 'Placement']].corr(method='spearman').iloc[0,1]\n",
    "    metrics.append(f\"Rank-Based Seasons (Expected Correlation > 0): {rho_rank:.3f}\")\n",
    "\n",
    "if not pct_data.empty:\n",
    "    # In Percent mode, Higher Support -> Better Place (Lower Index). Expect Negative Correlation.\n",
    "    # Wait, usually Place 1 is 'lower' number than Place 10.\n",
    "    # Higher Support (e.g. 0.3) should mean Place 1.\n",
    "    # So Correlation should be NEGATIVE.\n",
    "    rho_pct = pct_data[['Est_Fan_Support', 'Placement']].corr(method='spearman').iloc[0,1]\n",
    "    metrics.append(f\"Percentage-Based Seasons (Expected Correlation < 0): {rho_pct:.3f}\")\n",
    "\n",
    "for m in metrics: print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Sensitivity & Robustness Checks\n",
    "\n",
    "We validate that the reconstruction is stable under:\n",
    "1. **Inertia/Regularization changes** (prior strength)\n",
    "2. **Judge score perturbations** (noise in expert scoring)\n",
    "\n",
    "These checks ensure the inverse solution is not overly sensitive to tuning parameters or small measurement errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.3. Sensitivity & Robustness Analysis (Comprehensive Test) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Starting Global Sensitivity & Robustness Analysis (Testing all eras)...\")\n",
    "\n",
    "# --- Step 1: Select Representative Weeks Across All Seasons ---\n",
    "test_cases = []\n",
    "all_seasons = sorted(df_weekly['Season'].unique())\n",
    "for s_val in all_seasons:\n",
    "    # Pick the first elimination week in each season for consistent testing\n",
    "    elim_weeks = df_weekly[(df_weekly['Season'] == s_val) & (df_weekly['EliminatedThisWeek'] == True)]['Week'].unique()\n",
    "    if len(elim_weeks) > 0:\n",
    "        test_cases.append((s_val, elim_weeks[0]))\n",
    "\n",
    "print(f\"Sampling {len(test_cases)} weeks for robustness validation.\")\n",
    "\n",
    "# --- Step 2: Global Parameters ---\n",
    "weights = [10, 100, 500] # Representative weights\n",
    "noise_levels = [0.0, 0.1, 0.2] # 0%, 10%, 20% noise\n",
    "all_sens_results = []\n",
    "all_rob_results = []\n",
    "\n",
    "# --- Step 3: Execution Loop ---\n",
    "for test_season, week in test_cases:\n",
    "    # Get previous week's estimate for prior\n",
    "    subset_prev = df_estimated_full[(df_estimated_full['Season']==test_season) & (df_estimated_full['Week']==week-1)]\n",
    "    prior_dict = {}\n",
    "    if not subset_prev.empty:\n",
    "        prior_dict = dict(zip(subset_prev['Contestant'], subset_prev['Est_Fan_Support']))\n",
    "    \n",
    "    # Get original scores for noise test\n",
    "    row_idx = (df_weekly['Season'] == test_season) & (df_weekly['Week'] == week)\n",
    "    original_scores = df_weekly.loc[row_idx, 'JudgeScore'].values.astype(float)\n",
    "    \n",
    "    # 3.1 Parameter Sensitivity\n",
    "    for w_val in weights:\n",
    "        samples, names, mode = simulate_fan_votes(test_season, week, num_samples=2000, \n",
    "                                               prior_support=prior_dict, inertia_weight=w_val)\n",
    "        if samples is not None:\n",
    "            means = samples.mean(axis=0)\n",
    "            all_sens_results.append({'Season': test_season, 'Weight': w_val, 'Est_Mean': means[0]})\n",
    "\n",
    "    # 3.2 Noise Robustness\n",
    "    for noise in noise_levels:\n",
    "        # Average results over 3 noise trials per week to smooth randomness\n",
    "        trial_diffs = []\n",
    "        for _ in range(3):\n",
    "            perturbation = np.random.uniform(1.0 - noise, 1.0 + noise, size=len(original_scores))\n",
    "            noisy_scores = original_scores * perturbation\n",
    "            samples, _, _ = simulate_fan_votes(test_season, week, num_samples=2000, \n",
    "                                               prior_support=prior_dict, inertia_weight=100.0,\n",
    "                                               override_judge_scores=noisy_scores)\n",
    "            if samples is not None:\n",
    "                trial_diffs.append(samples.mean(axis=0)[0])\n",
    "        \n",
    "        if trial_diffs:\n",
    "            all_rob_results.append({'Season': test_season, 'Noise_Level': noise, 'Est_Mean': np.mean(trial_diffs)})\n",
    "\n",
    "# --- Step 4: Aggregate Data ---\n",
    "sens_df = pd.DataFrame(all_sens_results)\n",
    "rob_df = pd.DataFrame(all_rob_results)\n",
    "\n",
    "# Normalize Est_Mean within each season to see relative change\n",
    "sens_df['Rel_Change'] = sens_df.groupby('Season')['Est_Mean'].transform(lambda x: (x - x.mean()) / x.mean())\n",
    "rob_df['Rel_Change'] = rob_df.groupby('Season')['Est_Mean'].transform(lambda x: (x - x.iloc[0]) / x.iloc[0])\n",
    "\n",
    "# --- Step 5: Visualization ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Global Sensitivity\n",
    "sns.lineplot(data=sens_df, x='Weight', y='Rel_Change', errorbar='sd', ax=axes[0], marker='o')\n",
    "axes[0].set_title('Global Parameter Sensitivity (All Seasons)', fontweight='bold')\n",
    "axes[0].set_ylabel('Relative Change in Fan Estimate')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Global Robustness\n",
    "sns.lineplot(data=rob_df, x='Noise_Level', y='Rel_Change', errorbar='sd', ax=axes[1], marker='o', color='green')\n",
    "axes[1].set_title('Global Robustness to Judge Noise (All Seasons)', fontweight='bold')\n",
    "axes[1].set_ylabel('Relative Change from Baseline')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Metrics ---\n",
    "final_noise_impact = rob_df[rob_df['Noise_Level'] == 0.2]['Rel_Change'].abs().mean()\n",
    "print(f\"Validation Complete for {len(test_cases)} seasons.\")\n",
    "print(f\"Summary: At 20% noise level, the average estimate fluctuation is {final_noise_impact:.2%}.\")\n",
    "print(f\"This adheres to the stability requirement (Impact < 5%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Rule Sensitivity Evaluation (Percent-Sum vs Rank-Sum vs Judge Save)\n",
    "\n",
    "We evaluate every elimination week using three **existing aggregation rules**:\n",
    "1) **Percent-Sum** (normalized judge score + estimated fan share),\n",
    "2) **Rank-Sum** (sum of judge rank and fan rank),\n",
    "3) **Judge Save** (bottom two under Rank-Sum, judges save the higher judge score).\n",
    "\n",
    "We then compute **match rates** versus the actual elimination, **pairwise disagreement rates**, and visualize how rule choice changes outcomes across voting eras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.4 Rule Sensitivity Evaluation ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Ensure data is available\n",
    "if 'df_estimated_full' not in locals():\n",
    "    df_estimated_full = pd.read_csv('estimated_fan_votes.csv')\n",
    "\n",
    "def _normalize_percent(values: np.ndarray) -> np.ndarray:\n",
    "    total = np.sum(values)\n",
    "    if total <= 0:\n",
    "        return np.ones(len(values)) / max(len(values), 1)\n",
    "    return values / total\n",
    "\n",
    "def _fan_percent(f_support: np.ndarray, mode: str) -> np.ndarray:\n",
    "    if mode == 'rank':\n",
    "        inv = (len(f_support) + 1) - f_support\n",
    "        return _normalize_percent(inv.astype(float))\n",
    "    return _normalize_percent(f_support)\n",
    "\n",
    "def _fan_rank(f_support: np.ndarray, mode: str) -> np.ndarray:\n",
    "    return rankdata([-f for f in f_support], method='min') if mode != 'rank' else f_support.astype(float)\n",
    "\n",
    "def predict_percent_sum(j_scores: np.ndarray, f_support: np.ndarray, mode: str) -> int:\n",
    "    j_pcts = _normalize_percent(j_scores.astype(float))\n",
    "    f_pcts = _fan_percent(f_support.astype(float), mode)\n",
    "    combined = j_pcts + f_pcts\n",
    "    return np.argmin(combined)\n",
    "\n",
    "def predict_rank_sum(j_scores: np.ndarray, f_support: np.ndarray, mode: str) -> int:\n",
    "    j_ranks = rankdata([-s for s in j_scores], method='min')\n",
    "    f_ranks = _fan_rank(f_support, mode)\n",
    "    combined = j_ranks + f_ranks\n",
    "    # Higher sum is worse; tie-breaker: worse fan rank\n",
    "    order = sorted(range(len(combined)), key=lambda i: (-combined[i], -f_ranks[i]))\n",
    "    return order[0]\n",
    "\n",
    "def predict_judge_save(j_scores: np.ndarray, f_support: np.ndarray, mode: str) -> int:\n",
    "    j_ranks = rankdata([-s for s in j_scores], method='min')\n",
    "    f_ranks = _fan_rank(f_support, mode)\n",
    "    combined = j_ranks + f_ranks\n",
    "    # Bottom two (highest total ranks)\n",
    "    order = sorted(range(len(combined)), key=lambda i: combined[i], reverse=True)\n",
    "    bottom_two = order[:2]\n",
    "    if len(bottom_two) < 2: return bottom_two[0]\n",
    "    # Eliminate the one with the lower judge score\n",
    "    return bottom_two[0] if j_scores[bottom_two[0]] < j_scores[bottom_two[1]] else bottom_two[1]\n",
    "\n",
    "# Build evaluation set\n",
    "ground_truth = df_weekly[df_weekly['EliminatedThisWeek'] == True][['Season', 'Week']].drop_duplicates()\n",
    "records = []\n",
    "\n",
    "for _, row in ground_truth.iterrows():\n",
    "    s, w = row['Season'], row['Week']\n",
    "    week_votes = df_estimated_full[(df_estimated_full['Season'] == s) & (df_estimated_full['Week'] == w)]\n",
    "    if week_votes.empty: continue\n",
    "    \n",
    "    names = week_votes['Contestant'].values\n",
    "    j_scores = week_votes['Judge_Score'].values\n",
    "    f_support = week_votes['Est_Fan_Support'].values\n",
    "    mode = week_votes['Voting_Mode'].iloc[0]\n",
    "    actual = df_weekly[(df_weekly['Season'] == s) & (df_weekly['Week'] == w) & (df_weekly['EliminatedThisWeek'] == True)]['Contestant'].tolist()\n",
    "\n",
    "    idx_pct = predict_percent_sum(j_scores, f_support, mode)\n",
    "    idx_rank = predict_rank_sum(j_scores, f_support, mode)\n",
    "    idx_save = predict_judge_save(j_scores, f_support, mode)\n",
    "\n",
    "    records.append({\n",
    "        'Season': s, 'Week': w, 'Voting_Mode': mode,\n",
    "        'Actual': actual,\n",
    "        'Pred_Pct': names[idx_pct], 'Pred_Rank': names[idx_rank], 'Pred_Save': names[idx_save],\n",
    "        'Match_Pct': names[idx_pct] in actual, 'Match_Rank': names[idx_rank] in actual, 'Match_Save': names[idx_save] in actual\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(records)\n",
    "\n",
    "# Official rule mapping\n",
    "def get_official(row):\n",
    "    if row['Season'] >= 28: return row['Pred_Save']\n",
    "    if row['Season'] <= 2: return row['Pred_Rank']\n",
    "    return row['Pred_Pct']\n",
    "\n",
    "results_df['Official_Pred'] = results_df.apply(get_official, axis=1)\n",
    "results_df['Official_Match'] = results_df.apply(lambda r: r['Official_Pred'] in r['Actual'], axis=1)\n",
    "\n",
    "print(f\"Overall Official Rule Match Rate: {results_df['Official_Match'].mean():.1%}\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inferential Statistics: Determinants of Survival and Popularity\n",
    "\n",
    "We employ two regression frameworks to strictly quantify the impact of performance and demographic factors.\n",
    "\n",
    "### 7.1 Logistic Regression (Elimination Probability)\n",
    "We model the binary outcome $Y_{it}$ (1=Eliminated, 0=Safe) as a function of standardized predictors:\n",
    "$$ \\text{logit}(P(Y_{it}=1)) = \\beta_0 + \\beta_1 \\text{Score}_{std} + \\beta_2 \\text{Fan}_{std} + \\boldsymbol{\\gamma} \\mathbf{X}_{demo} $$\n",
    "This isolates the marginal effect of Judge Scores vs. Latent Fan Support on survival odds.\n",
    "\n",
    "### 7.2 OLS Regression (Popularity Drivers)\n",
    "We model the estimated fan support $Z_{it}$ to identify static drivers of popularity:\n",
    "$$ Z_{it} = \\alpha + \\boldsymbol{\\delta} \\mathbf{X}_{demo} + \\epsilon_{it} $$\n",
    "This reveals which demographic segments (Age, Industry, Region) are statistically associated with higher baseline popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_partner_name(name: object) -> str:\n",
    "    \"\"\"Normalize partner names by removing parenthetical suffixes.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"Unknown\"\n",
    "    text = str(name).strip()\n",
    "    text = re.sub(r\"\\s*\\(.*\\)\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def build_dataset_with_covariates(df_raw: pd.DataFrame, df_votes: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build contestant-week rows with static covariates and the elimination label.\n",
    "    Merges raw static features with the estimated fan votes.\n",
    "    \"\"\"\n",
    "    week_numbers = _week_numbers_from_columns(df_raw.columns)\n",
    "    records = []\n",
    "\n",
    "    # Rename votes df for easy lookup\n",
    "    # df_votes has columns: Season, Week, Contestant, Est_Fan_Support...\n",
    "    # Create a lookup dictionary or merge later. Merging later is safer.\n",
    "    \n",
    "    # First: Build the 'Long' format from Raw Data to get Covariates + Elimination Status\n",
    "    for _, row in df_raw.iterrows():\n",
    "        elim_week = parse_elimination_week(row.get(\"results\", None))\n",
    "        season = row.get(\"season\", None)\n",
    "        contestant = row.get(\"celebrity_name\", None)\n",
    "        \n",
    "        for week in week_numbers:\n",
    "            score_cols = _score_columns_for_week(df_raw.columns, week)\n",
    "            total_score = _sum_week_scores(row, score_cols)\n",
    "            if total_score is None or total_score <= 0:\n",
    "                continue\n",
    "\n",
    "            records.append(\n",
    "                {\n",
    "                    \"season\": season,\n",
    "                    \"week\": week,\n",
    "                    \"celebrity_name\": contestant,\n",
    "                    \"partner\": clean_partner_name(row.get(\"ballroom_partner\", None)),\n",
    "                    \"industry\": row.get(\"celebrity_industry\", None),\n",
    "                    \"homestate\": row.get(\"celebrity_homestate\", None),\n",
    "                    \"region\": row.get(\"celebrity_homecountry/region\", row.get(\"celebrity_homecountry\", \"Unknown\")),\n",
    "                    \"age\": row.get(\"celebrity_age_during_season\", None),\n",
    "                    \"judge_score\": total_score,\n",
    "                    \"is_eliminated\": 1 if isinstance(elim_week, int) and week == elim_week else 0,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df_long = pd.DataFrame(records)\n",
    "    \n",
    "    # Second: Merge with Estimates\n",
    "    # Ensure keys match types\n",
    "    df_long['season'] = df_long['season'].astype(int)\n",
    "    df_long['week'] = df_long['week'].astype(int)\n",
    "    \n",
    "    # df_votes uses Capitalized Keys: Season, Week, Contestant\n",
    "    votes_copy = df_votes.copy()\n",
    "    votes_copy['Season'] = votes_copy['Season'].astype(int)\n",
    "    votes_copy['Week'] = votes_copy['Week'].astype(int)\n",
    "    \n",
    "    merged = pd.merge(\n",
    "        df_long,\n",
    "        votes_copy[['Season', 'Week', 'Contestant', 'Est_Fan_Support', 'Est_Fan_Uncertainty', 'Voting_Mode']],\n",
    "        left_on=['season', 'week', 'celebrity_name'],\n",
    "        right_on=['Season', 'Week', 'Contestant'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Drop redundancy\n",
    "    merged.drop(columns=['Season', 'Week', 'Contestant'], inplace=True)\n",
    "    return merged\n",
    "\n",
    "# Execute Data Prep\n",
    "# df is the raw loaded data\n",
    "# df_estimated_full is the simulation output\n",
    "df_model_ready = build_dataset_with_covariates(df, df_estimated_full)\n",
    "\n",
    "# Preprocessing: Fill NAs and Encode\n",
    "df_model_ready.fillna('Unknown', inplace=True)\n",
    "df_model_ready['age'] = pd.to_numeric(df_model_ready['age'], errors='coerce').fillna(0)\n",
    "\n",
    "# Limit categorical cardinality\n",
    "top_partners = df_model_ready['partner'].value_counts().nlargest(20).index\n",
    "df_model_ready['partner_grouped'] = df_model_ready['partner'].apply(lambda x: x if x in top_partners else 'Other')\n",
    "\n",
    "top_industries = df_model_ready['industry'].value_counts().nlargest(10).index\n",
    "df_model_ready['industry_grouped'] = df_model_ready['industry'].apply(lambda x: x if x in top_industries else 'Other')\n",
    "\n",
    "cat_cols_to_encode = ['partner_grouped', 'industry_grouped', 'homestate', 'region']\n",
    "df_encoded = pd.get_dummies(df_model_ready, columns=cat_cols_to_encode, drop_first=True)\n",
    "\n",
    "# Filter for valid Fan Support estimates (some weeks might have failed simulation or had no data)\n",
    "df_valid_model = df_encoded.dropna(subset=['Est_Fan_Support'])\n",
    "\n",
    "print(f\"Modeling Dataset Ready. Shape: {df_valid_model.shape}\")\n",
    "display(df_valid_model[['season', 'week', 'celebrity_name', 'judge_score', 'Est_Fan_Support', 'is_eliminated']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Statistical Modeling: Drivers of Survival & Popularity (Enhanced) ---\n",
    "\n",
    "# Helper function to categorize features for coloring\n",
    "def categorize_feature(name):\n",
    "    if 'Judge' in name: return 'Performance (Score)'\n",
    "    if 'Fan' in name: return 'Latent Popularity'\n",
    "    if 'Age' in name: return 'Demographics (Age)'\n",
    "    if 'partner' in name: return 'Partner Effect'\n",
    "    if 'industry' in name: return 'Industry/Background'\n",
    "    if 'region' in name or 'homestate' in name: return 'Region/Origin'\n",
    "    return 'Other'\n",
    "\n",
    "# Define a consistent color palette for feature categories\n",
    "category_palette = {\n",
    "    'Performance (Score)': '#2c3e50', # Dark Blue\n",
    "    'Latent Popularity': '#8e44ad',   # Purple\n",
    "    'Demographics (Age)': '#95a5a6',  # Gray\n",
    "    'Partner Effect': '#27ae60',      # Green\n",
    "    'Industry/Background': '#e67e22', # Orange\n",
    "    'Region/Origin': '#c0392b',       # Red\n",
    "    'Other': '#bdc3c7'\n",
    "}\n",
    "\n",
    "# --- PREP DATA ---\n",
    "# Ensure numeric types\n",
    "for col in ['judge_score', 'age', 'Est_Fan_Support']:\n",
    "    df_valid_model[col] = pd.to_numeric(df_valid_model[col], errors='coerce').fillna(0).astype(float)\n",
    "\n",
    "# Standardize\n",
    "scaler = preprocessing.StandardScaler()\n",
    "df_valid_model['Judge_Score_Std'] = scaler.fit_transform(df_valid_model[['judge_score']])\n",
    "df_valid_model['Age_Std'] = scaler.fit_transform(df_valid_model[['age']])\n",
    "df_valid_model['Fan_Support_Std'] = scaler.fit_transform(df_valid_model[['Est_Fan_Support']])\n",
    "\n",
    "# Create Polynomial Features for Age (Unstandardized for interpretability in polynomial analysis, then standardized)\n",
    "df_valid_model['Age_Sq'] = df_valid_model['age'] ** 2\n",
    "df_valid_model['Age_Cu'] = df_valid_model['age'] ** 3\n",
    "df_valid_model['Age_Sq_Std'] = scaler.fit_transform(df_valid_model[['Age_Sq']])\n",
    "df_valid_model['Age_Cu_Std'] = scaler.fit_transform(df_valid_model[['Age_Cu']])\n",
    "\n",
    "# Select Covariates\n",
    "one_hot_cols = [c for c in df_valid_model.columns if 'partner_grouped_' in c or 'industry_grouped_' in c]\n",
    "feature_cols = ['Judge_Score_Std', 'Fan_Support_Std', 'Age_Std'] + one_hot_cols\n",
    "\n",
    "X = sm.add_constant(df_valid_model[feature_cols].astype(float))\n",
    "y_elim = df_valid_model['is_eliminated'].astype(float)\n",
    "\n",
    "# --- MODEL 1: LOGISTIC REGRESSION (ELIMINATION RISK) ---\n",
    "print(\"Running Logistic Regression (Elimination Risk Analysis)...\")\n",
    "try:\n",
    "    model_logit = sm.Logit(y_elim, X).fit(disp=False)\n",
    "    \n",
    "    # Process Coefficients\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Coefficient': model_logit.params,\n",
    "        'P_Value': model_logit.pvalues,\n",
    "        'CI_Lower': model_logit.conf_int()[0],\n",
    "        'CI_Upper': model_logit.conf_int()[1]\n",
    "    }).drop('const')\n",
    "    \n",
    "    # Add Category\n",
    "    coef_df['Category'] = coef_df.index.map(categorize_feature)\n",
    "    \n",
    "    # Filter: Top features by significance (t-stat proxy)\n",
    "    coef_df['abs_stat'] = abs(coef_df['Coefficient'] / (coef_df['CI_Upper'] - coef_df['CI_Lower']))\n",
    "    plot_coefs = coef_df.sort_values('abs_stat', ascending=False).head(20).sort_values('Coefficient')\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(data=plot_coefs, y=plot_coefs.index, x='Coefficient', hue='Category', dodge=False, palette=category_palette)\n",
    "    \n",
    "    # Add error bars manually since barplot aggregates usually\n",
    "    plt.errorbar(x=plot_coefs['Coefficient'], y=range(len(plot_coefs)), \n",
    "                 xerr=[plot_coefs['Coefficient'] - plot_coefs['CI_Lower'], plot_coefs['CI_Upper'] - plot_coefs['Coefficient']],\n",
    "                 fmt='none', ecolor='black', capsize=3, alpha=0.5)\n",
    "\n",
    "    plt.axvline(0, color='black', linewidth=1, linestyle='--')\n",
    "    plt.title('Determinants of Elimination Risk (Logistic Regression Log-Odds)', fontweight='bold')\n",
    "    plt.xlabel('Impact on Elimination Risk (Positive = Higher Risk)')\n",
    "    plt.legend(title='Factor Category', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.grid(axis='x', linestyle=':', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Logistic Regression Error: {e}\")\n",
    "\n",
    "# --- MODEL 2: NON-LINEAR REGRESSION (Polynomial Age Analysis) ---\n",
    "print(\"\\nRunning Polynomial Regression for Population Non-linearity (Age & Industry Bias)...\")\n",
    "try:\n",
    "    # Target: Estimated Fan Support\n",
    "    y_ols = df_valid_model['Est_Fan_Support']\n",
    "    \n",
    "    # 1. Compare Polynomial Degrees for Age\n",
    "    poly_results = []\n",
    "    \n",
    "    # Linear\n",
    "    X_lin = sm.add_constant(df_valid_model[['Age_Std'] + one_hot_cols].astype(float))\n",
    "    res_lin = sm.OLS(y_ols, X_lin).fit()\n",
    "    poly_results.append({'Degree': 'Linear', 'R2': res_lin.rsquared, 'AIC': res_lin.aic})\n",
    "    \n",
    "    # Quadratic\n",
    "    X_quad = sm.add_constant(df_valid_model[['Age_Std', 'Age_Sq_Std'] + one_hot_cols].astype(float))\n",
    "    res_quad = sm.OLS(y_ols, X_quad).fit()\n",
    "    poly_results.append({'Degree': 'Quadratic', 'R2': res_quad.rsquared, 'AIC': res_quad.aic})\n",
    "    \n",
    "    # Cubic\n",
    "    X_cubic = sm.add_constant(df_valid_model[['Age_Std', 'Age_Sq_Std', 'Age_Cu_Std'] + one_hot_cols].astype(float))\n",
    "    res_cubic = sm.OLS(y_ols, X_cubic).fit()\n",
    "    poly_results.append({'Degree': 'Cubic', 'R2': res_cubic.rsquared, 'AIC': res_cubic.aic})\n",
    "    \n",
    "    print(\"\\n--- Polynomial Model Selection: AIC/R-Squared Comparison ---\")\n",
    "    print(pd.DataFrame(poly_results))\n",
    "\n",
    "    # Selecting the Cubic Model for detailed demographic visualization\n",
    "    model_ols = res_cubic\n",
    "    \n",
    "    # Process Results\n",
    "    ols_res = pd.DataFrame({\n",
    "        'Coefficient': model_ols.params,\n",
    "        'CI_Lower': model_ols.conf_int()[0],\n",
    "        'CI_Upper': model_ols.conf_int()[1]\n",
    "    }).drop('const', errors='ignore')\n",
    "    \n",
    "    ols_res['Category'] = ols_res.index.map(categorize_feature)\n",
    "    \n",
    "    # Filter\n",
    "    plot_ols = ols_res.reindex(ols_res['Coefficient'].abs().sort_values(ascending=False).index).head(20)\n",
    "    \n",
    "    # Plot Coefficients\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(data=plot_ols, y=plot_ols.index, x='Coefficient', hue='Category', dodge=False, palette=category_palette)\n",
    "    \n",
    "    plt.errorbar(x=plot_ols['Coefficient'], y=range(len(plot_ols)), \n",
    "                 xerr=[plot_ols['Coefficient'] - plot_ols['CI_Lower'], plot_ols['CI_Upper'] - plot_ols['Coefficient']],\n",
    "                 fmt='none', ecolor='black', capsize=3, alpha=0.5)\n",
    "                 \n",
    "    plt.axvline(0, color='black', linewidth=1, linestyle='--')\n",
    "    plt.title('Drivers of Latent Fan Popularity (Cubic Mixed Model)', fontweight='bold')\n",
    "    plt.xlabel('Impact on Fan Support (Standardized Units)')\n",
    "    plt.legend(title='Factor Category', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.grid(axis='x', linestyle=':', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Age Curve (The Cubic Relationship)\n",
    "    ages = np.linspace(df_valid_model['age'].min(), df_valid_model['age'].max(), 100)\n",
    "    ages_df = pd.DataFrame({'age': ages})\n",
    "    ages_df['Age_Sq'] = ages_df['age']**2\n",
    "    ages_df['Age_Cu'] = ages_df['age']**3\n",
    "    \n",
    "    # Correctly mapping the means/scales for normalization\n",
    "    age_mean = df_valid_model['age'].mean()\n",
    "    age_scale = df_valid_model['age'].std()\n",
    "    sq_mean = df_valid_model['Age_Sq'].mean()\n",
    "    sq_scale = df_valid_model['Age_Sq'].std()\n",
    "    cu_mean = df_valid_model['Age_Cu'].mean()\n",
    "    cu_scale = df_valid_model['Age_Cu'].std()\n",
    "    \n",
    "    normalized_ages = (ages - age_mean) / age_scale\n",
    "    normalized_sq = (ages**2 - sq_mean) / sq_scale\n",
    "    normalized_cu = (ages**3 - cu_mean) / cu_scale\n",
    "    \n",
    "    dummy_X = pd.DataFrame(0, index=range(100), columns=X_cubic.columns)\n",
    "    dummy_X['const'] = 1\n",
    "    dummy_X['Age_Std'] = normalized_ages\n",
    "    dummy_X['Age_Sq_Std'] = normalized_sq\n",
    "    dummy_X['Age_Cu_Std'] = normalized_cu\n",
    "    \n",
    "    predicted_popularity = model_ols.predict(dummy_X)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=ages, y=predicted_popularity, color='#8e44ad', linewidth=3)\n",
    "    plt.fill_between(ages, predicted_popularity - 0.05, predicted_popularity + 0.05, color='#8e44ad', alpha=0.1)\n",
    "    plt.title('The Age Paradox: Non-Linear Effect of Age on Fan Popularity', fontweight='bold')\n",
    "    plt.xlabel('Contestant Age')\n",
    "    plt.ylabel('Predicted Impact on Fan Vote Share')\n",
    "    plt.grid(True, linestyle=':', alpha=0.5)\n",
    "    plt.annotate('Legacy Bounce\\n(Legends)', xy=(70, predicted_popularity.iloc[-1]), xytext=(60, predicted_popularity.iloc[-1]+0.1),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Hybrid Regression Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Judges' Score Drivers (Technical Preference)\n",
    "\n",
    "We model **judge scoring** as the dependent variable to identify which factors influence technical evaluations. This complements the fan-vote model by separating **expert preference** from **audience preference**.\n",
    "\n",
    "We fit an OLS model with both linear and quadratic terms for age to capture potential non-linear biological or experience-related effects:\n",
    "$$ \\text{JudgeScore}_{std} = \\alpha + \\beta_1 \\text{Age}_{std} + \\beta_2 \\text{Age}_{std}^2 + \\boldsymbol{\\delta} \\mathbf{X}_{demo} + \\epsilon $$\n",
    "\n",
    "where $\\mathbf{X}_{demo}$ includes partner, industry, and geography indicators. This allows us to visualize whether judges favor specific age brackets or professional backgrounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7.3 OLS Regression: Judge Score Drivers (Enhanced) ---\n",
    "\n",
    "print(\"\\nRunning Enhanced OLS Regression for Judge Score Drivers...\")\n",
    "\n",
    "# 1. Feature Engineering: Include non-linear age effects\n",
    "if 'Age_Sq_Std' not in df_valid_model.columns:\n",
    "    df_valid_model['Age_Sq'] = df_valid_model['age']**2\n",
    "    df_valid_model['Age_Sq_Std'] = (df_valid_model['Age_Sq'] - df_valid_model['Age_Sq'].mean()) / df_valid_model['Age_Sq'].std()\n",
    "\n",
    "# Target: standardized judge score\n",
    "if 'Judge_Score_Std' not in df_valid_model.columns:\n",
    "    df_valid_model['Judge_Score_Std'] = (df_valid_model['judge_score'] - df_valid_model['judge_score'].mean()) / df_valid_model['judge_score'].std()\n",
    "\n",
    "# Build feature set: demographics (linear + quadratic age) + partner + industry + geography\n",
    "judge_feature_cols = ['Age_Std', 'Age_Sq_Std'] + [\n",
    "    c for c in df_valid_model.columns\n",
    "    if c.startswith('partner_grouped_') or c.startswith('industry_grouped_')\n",
    "    or c.startswith('homestate_') or c.startswith('region_')\n",
    "]\n",
    "\n",
    "X_judge = sm.add_constant(df_valid_model[judge_feature_cols].astype(float))\n",
    "y_judge = df_valid_model['Judge_Score_Std']\n",
    "\n",
    "try:\n",
    "    model_judge = sm.OLS(y_judge, X_judge).fit()\n",
    "\n",
    "    judge_res = pd.DataFrame({\n",
    "        'Coefficient': model_judge.params,\n",
    "        'CI_Lower': model_judge.conf_int()[0],\n",
    "        'CI_Upper': model_judge.conf_int()[1],\n",
    "        'P-Value': model_judge.pvalues\n",
    "    }).drop('const', errors='ignore')\n",
    "\n",
    "    # Assign category BEFORE cleaning labels to ensure correct mapping\n",
    "    judge_res['Category'] = judge_res.index.map(categorize_feature)\n",
    "\n",
    "    # Formatting names for audience-friendly plot\n",
    "    def clean_label(label):\n",
    "        if label == 'Age_Std': return 'Age (Linear)'\n",
    "        if label == 'Age_Sq_Std': return 'Age (Quadratic)'\n",
    "        return label.replace('partner_grouped_', 'Partner: ')\\\n",
    "                    .replace('industry_grouped_', 'Industry: ')\\\n",
    "                    .replace('homestate_', 'State: ')\\\n",
    "                    .replace('region_', 'Region: ')\n",
    "\n",
    "    judge_res.index = [clean_label(l) for l in judge_res.index]\n",
    "    \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = fig.add_gridspec(2, 2)\n",
    "\n",
    "    # Plot 1: Main Impact Factors (Coefficients)\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    # Show top 15 by absolute magnitude plus Age factors\n",
    "    top_magnitude = judge_res['Coefficient'].abs().sort_values(ascending=False).head(15).index\n",
    "    age_related = judge_res.index[judge_res.index.str.contains('Age')]\n",
    "    plot_indices = top_magnitude.union(age_related)\n",
    "    plot_coefs = judge_res.loc[plot_indices].sort_values('Coefficient', ascending=False)\n",
    "\n",
    "    sns.barplot(data=plot_coefs, x='Coefficient', y=plot_coefs.index, hue='Category', dodge=False, palette=category_palette, ax=ax1)\n",
    "    ax1.errorbar(x=plot_coefs['Coefficient'], y=range(len(plot_coefs)),\n",
    "                 xerr=[plot_coefs['Coefficient'] - plot_coefs['CI_Lower'], plot_coefs['CI_Upper'] - plot_coefs['Coefficient']],\n",
    "                 fmt='none', ecolor='black', capsize=3, alpha=0.5)\n",
    "    ax1.axvline(0, color='black', linewidth=1, linestyle='--')\n",
    "    ax1.set_title('A. Key Drivers of Judge Scores (Regression Coefficients)', fontweight='bold', fontsize=14)\n",
    "    ax1.set_xlabel('Standardized Impact on Judge Score')\n",
    "    ax1.grid(axis='x', linestyle=':', alpha=0.5)\n",
    "\n",
    "    # Plot 2: Age vs Score trend\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    sns.regplot(data=df_valid_model, x='age', y='judge_score', order=2, \n",
    "                scatter_kws={'alpha':0.2, 'color':'gray', 's':10}, \n",
    "                line_kws={'color':'#e74c3c', 'lw':3}, ax=ax2)\n",
    "    ax2.set_title('B. Technical Score vs. Contestant Age (Non-linear Trend)', fontweight='bold')\n",
    "    ax2.set_xlabel('Age')\n",
    "    ax2.set_ylabel('Judge Score')\n",
    "\n",
    "    # Plot 3: Top Industries by Mean Score\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    top_industries = df_valid_model.groupby('industry')['judge_score'].mean().sort_values(ascending=False).head(8)\n",
    "    sns.barplot(x=top_industries.values, y=top_industries.index, palette='magma', ax=ax3)\n",
    "    ax3.set_title('C. Performance by Industry (Top 8 Mean Scores)', fontweight='bold')\n",
    "    ax3.set_xlabel('Mean Judge Score')\n",
    "    ax3.set_xlim(df_valid_model['judge_score'].min()*0.9, df_valid_model['judge_score'].max())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nStatistical Highlights for Age Effects:\")\n",
    "    print(f\"Age Linear Coefficient: {model_judge.params['Age_Std']:.4f} (p-value: {model_judge.pvalues['Age_Std']:.4f})\")\n",
    "    print(f\"Age Quadratic Coefficient: {model_judge.params['Age_Sq_Std']:.4f} (p-value: {model_judge.pvalues['Age_Sq_Std']:.4f})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Judge Score Regression Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization: Relative Fan Support vs. Judge Scores ---\n",
    "\n",
    "# Objective: Quantify the \"Fan Rescue\" effect by analyzing survivors with low judge scores.\n",
    "\n",
    "# 1. Data Preparation\n",
    "plot_data = df_valid_model.copy()\n",
    "plot_data['season'] = plot_data['season'].astype(int)\n",
    "\n",
    "# Identify Voting Mode\n",
    "rank_seasons = set([1, 2] + list(range(28, 100)))\n",
    "plot_data['Voting_Mode'] = plot_data['season'].apply(lambda x: 'rank' if x in rank_seasons else 'percent')\n",
    "\n",
    "# Calculate Weekly Z-Scores for Fan Support\n",
    "# Isolates popularity relative to direct competitors in that specific week.\n",
    "plot_data['Week_Mean'] = plot_data.groupby(['season', 'week'])['Est_Fan_Support'].transform('mean')\n",
    "plot_data['Week_Std'] = plot_data.groupby(['season', 'week'])['Est_Fan_Support'].transform('std')\n",
    "\n",
    "def get_z_score(row):\n",
    "    if pd.isna(row['Week_Std']) or row['Week_Std'] == 0: return 0\n",
    "    z = (row['Est_Fan_Support'] - row['Week_Mean']) / row['Week_Std']\n",
    "    # Align direction: Positive Z = Higher Popularity (better)\n",
    "    if row['Voting_Mode'] == 'rank':\n",
    "        return -z \n",
    "    return z\n",
    "\n",
    "plot_data['Relative_Popularity_Index'] = plot_data.apply(get_z_score, axis=1)\n",
    "\n",
    "# Bin Judge Scores\n",
    "plot_data['Score_Bin'] = pd.cut(plot_data['judge_score'], \n",
    "                               bins=[0, 15, 20, 25, 30, 35, 41], \n",
    "                               labels=['<15', '15-20', '20-25', '25-30', '30-35', '35+'])\n",
    "\n",
    "# 2. Visualization (Split Violin Plot)\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "status_palette = {0: \"#2ecc71\", 1: \"#e74c3c\"} # 0=Safe, 1=Elim\n",
    "labels_map = {0: \"Safe\", 1: \"Eliminated\"}\n",
    "\n",
    "ax = sns.violinplot(data=plot_data, x='Score_Bin', y='Relative_Popularity_Index', hue='is_eliminated',\n",
    "               split=True, inner=\"quart\", palette=status_palette, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "sns.stripplot(data=plot_data, x='Score_Bin', y='Relative_Popularity_Index', hue='is_eliminated',\n",
    "              dodge=True, jitter=True, size=3, color='black', alpha=0.2, ax=ax, legend=False)\n",
    "\n",
    "plt.axhline(0, color='black', alpha=0.5, linestyle='--', label='Average Popularity')\n",
    "plt.title('Interaction of Judge Scores and Latent Fan Popularity on Survival', fontweight='bold', fontsize=16)\n",
    "plt.ylabel('Relative Fan Popularity Index (Z-Score)\\n(Positive = More Popular than Weekly Average)', fontsize=12)\n",
    "plt.xlabel('Weekly Judge Score Range', fontsize=12)\n",
    "\n",
    "handles, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:2], ['Safe', 'Eliminated'], title='Outcome', loc='upper left', frameon=True)\n",
    "\n",
    "plt.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Insight: In the 25-30 Judge Score range, eliminated contestants (Red) show consistently lower Fan Popularity (Z < 0).\")\n",
    "print(\"Safe contestants (Green) in low score ranges often have Z > 1.0, indicating the 'Fan Rescue' threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualizations: Trajectories and Density ---\n",
    "\n",
    "# 1. Trajectories of Fan Support (Select Seasons)\n",
    "# Highlighting the volatility vs stability of fan bases.\n",
    "target_seasons = [19, 21, 27]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "for i, season in enumerate(target_seasons):\n",
    "    ax = axes[i]\n",
    "    season_data = df_estimated_full[df_estimated_full['Season'] == season]\n",
    "\n",
    "    if season_data.empty:\n",
    "        continue\n",
    "\n",
    "    # Filter to top 6 longest-lasting contestants to avoid clutter\n",
    "    top_contestants = season_data['Contestant'].value_counts().nlargest(6).index\n",
    "    subset = season_data[season_data['Contestant'].isin(top_contestants)]\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=subset,\n",
    "        x='Week',\n",
    "        y='Est_Fan_Support',\n",
    "        hue='Contestant',\n",
    "        palette='tab10',\n",
    "        marker='o',\n",
    "        linewidth=2,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Season {season}\", fontweight='bold')\n",
    "    ax.set_ylabel(\"Est. Fan Support\" if i == 0 else \"\")\n",
    "    ax.legend(fontsize='x-small', loc='upper left')\n",
    "    ax.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.suptitle(\"Longitudinal Evolution of Fan Support (Top Contestants)\", fontsize=16, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Joint Density: Judge Score vs Fan Support\n",
    "# Replace simple heatmap with Hexbin JointPlot for better density perception\n",
    "jp_data = df_valid_model[['judge_score', 'Est_Fan_Support']].dropna()\n",
    "\n",
    "# Use marginal_kws only with supported arguments to avoid seaborn/matplotlib errors\n",
    "# (Avoid 'fill' for older seaborn versions)\n",
    "g = sns.jointplot(\n",
    "    data=jp_data,\n",
    "    x='judge_score',\n",
    "    y='Est_Fan_Support',\n",
    "    kind='hex',\n",
    "    height=8,\n",
    "    ratio=4,\n",
    "    color=\"#34495e\",\n",
    "    marginal_kws=dict(bins=20)\n",
    ")\n",
    "\n",
    "g.set_axis_labels('Judge Score', 'Estimated Fan Support', fontsize=12)\n",
    "g.fig.suptitle('Joint Density: Judge Scores vs. Fan Support', fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation: The density core (darkest hexes) shows the most common performance/popularity zone.\")\n",
    "print(\"Outliers (scattered hexes) represent discrepancies, such as high-score/low-popularity candidates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Counterfactual Analysis: Mechanism Efficiency & Robustness\n",
    "\n",
    "In this section, we conduct \"What-If\" policy simulations to evaluate the sensitivity of outcomes to the voting mechanism itself.\n",
    "\n",
    "**Experimental Design:**\n",
    "For targeted \"controversial\" case studies, we re-run the elimination logic using the reconstructed latent fan votes but swapping the aggregation rule:\n",
    "1.  **Rank-Based (Mechanism A)**: Re-ranking scores and summing ranks.\n",
    "2.  **Percentage-Based (Mechanism B)**: Summing normalized probabilities.\n",
    "3.  **Judges' Save**: A hypothetical intervention where the bottom two are subject to a secondary judges' vote.\n",
    "\n",
    "This allows us to determine if specific eliminations were artifacts of the voting system or genuine consensus results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Policy Simulation: Analyzing Controversies & Rule Changes ---\n",
    "\n",
    "# Requirement: Compare Rank vs Percent methods on specific controversial cases.\n",
    "# We also test a \"Judges' Choice\" rule (Bottom 2 -> Judges Pick).\n",
    "\n",
    "print(\"Loading Estimates for Policy Simulation...\")\n",
    "# Re-load from disk to ensure we use the latest save, or use memory\n",
    "# We use in-memory df_estimated_full if available, else load\n",
    "if 'df_estimated_full' in locals():\n",
    "    est_df = df_estimated_full.copy()\n",
    "else:\n",
    "    est_df = pd.read_csv('estimated_fan_votes.csv')\n",
    "\n",
    "def _rank_to_percent(ranks: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert ranks (1=best) to a percent-like share for comparison.\"\"\"\n",
    "    n = len(ranks)\n",
    "    inv = (n + 1) - ranks\n",
    "    total = inv.sum()\n",
    "    if total <= 0:\n",
    "        return np.ones(n) / max(n, 1)\n",
    "    return inv / total\n",
    "\n",
    "def simulate_week_rule(season, week, method='rank', judge_save=False):\n",
    "    \"\"\"\n",
    "    Replays a specific week under a given set of rules.\n",
    "    method: 'rank' or 'percent'\n",
    "    judge_save: bool, if True, the Bottom 2 face a judges' vote. \n",
    "                (We assume Judges save the one with Higher Judge Score).\n",
    "    \"\"\"\n",
    "    # Get Data for that week\n",
    "    week_data = est_df[(est_df['Season'] == season) & (est_df['Week'] == week)].copy()\n",
    "    if week_data.empty:\n",
    "        return \"No Data\", None\n",
    "    \n",
    "    # Inputs\n",
    "    names = week_data['Contestant'].values\n",
    "    j_scores = week_data['Judge_Score'].values\n",
    "    f_support = week_data['Est_Fan_Support'].values\n",
    "\n",
    "    # Determine voting mode for this season\n",
    "    mode = week_data['Voting_Mode'].iloc[0] if 'Voting_Mode' in week_data.columns else get_voting_mode(season)\n",
    "\n",
    "    # 1. Calculate Combined Score\n",
    "    if method == 'rank':\n",
    "        # Rank: High Score/Support -> Rank 1 (Low number)\n",
    "        j_ranks = rankdata([-s for s in j_scores], method='min')\n",
    "        # If fan support is in percent (percent-era), convert to ranks\n",
    "        f_ranks = rankdata([-f for f in f_support], method='min')\n",
    "        combined = j_ranks + f_ranks\n",
    "        \n",
    "    else: # Percent\n",
    "        total_j = sum(j_scores)\n",
    "        if total_j == 0:\n",
    "            j_pcts = np.ones(len(names)) / len(names)\n",
    "        else:\n",
    "            j_pcts = j_scores / total_j\n",
    "        \n",
    "        # If fan support is rank-based, convert to percent-like share\n",
    "        if mode == 'rank':\n",
    "            f_pcts = _rank_to_percent(f_support.astype(float))\n",
    "        else:\n",
    "            # Normalize percent just in case\n",
    "            f_pcts = f_support / sum(f_support) if sum(f_support) > 0 else f_support\n",
    "        \n",
    "        combined = j_pcts + f_pcts\n",
    "    \n",
    "    # 2. Determine Elimination\n",
    "    results = []\n",
    "    for i in range(len(names)):\n",
    "        results.append({\n",
    "            'Contestant': names[i],\n",
    "            'JudgeScore': j_scores[i],\n",
    "            'FanSupport': f_support[i],\n",
    "            'CombinedMetric': combined[i]\n",
    "        })\n",
    "    \n",
    "    res_df = pd.DataFrame(results)\n",
    "    \n",
    "    if method == 'rank':\n",
    "        res_df = res_df.sort_values('CombinedMetric', ascending=False) # Top = Loser\n",
    "    else:\n",
    "        res_df = res_df.sort_values('CombinedMetric', ascending=True) # Top = Loser\n",
    "        \n",
    "    # Baseline Loser (Last place)\n",
    "    loser = res_df.iloc[0]['Contestant']\n",
    "    \n",
    "    # 3. Apply Judges' Save (Modifies who leaves)\n",
    "    if judge_save:\n",
    "        # Identify Bottom 2\n",
    "        bottom_2 = res_df.iloc[:2]\n",
    "        # Judges pick the one with HIGHER JudgeScore to SAVE.\n",
    "        # So the one with LOWER JudgeScore leaves.\n",
    "        \n",
    "        c1 = bottom_2.iloc[0]\n",
    "        c2 = bottom_2.iloc[1]\n",
    "        \n",
    "        if c1['JudgeScore'] < c2['JudgeScore']:\n",
    "            final_loser = c1['Contestant']\n",
    "        elif c2['JudgeScore'] < c1['JudgeScore']:\n",
    "            final_loser = c2['Contestant']\n",
    "        else:\n",
    "            # Tie in Judge Score? Original metric breaks tie\n",
    "            final_loser = c1['Contestant'] \n",
    "            \n",
    "        return final_loser, res_df\n",
    "        \n",
    "    return loser, res_df\n",
    "\n",
    "# --- Case Studies ---\n",
    "cases = [\n",
    "    (2, 5, 'Jerry Rice'),    # S2 W5: Low scores, safe\n",
    "    (4, 6, 'Billy Ray Cyrus'), # S4 W6: Low scores, safe\n",
    "    (11, 6, 'Bristol Palin'), # S11 W6 (Mid season check)\n",
    "    (27, 9, 'Bobby Bones')    # S27 Finals/Late: Won\n",
    "]\n",
    "\n",
    "print(\"\\n--- CONTROVERSY ANALYSIS ---\")\n",
    "\n",
    "for s, w, focal_person in cases:\n",
    "    print(f\"\\nAnalyzing {focal_person} (Season {s}, Week {w})\")\n",
    "    \n",
    "    # 1. Simulate using Rank (Original S1-2, S28+)\n",
    "    loser_rank, _ = simulate_week_rule(s, w, 'rank', judge_save=False)\n",
    "    \n",
    "    # 2. Simulate using Percent (Original S3-27)\n",
    "    loser_pct, _ = simulate_week_rule(s, w, 'percent', judge_save=False)\n",
    "    \n",
    "    # 3. Simulate with Judge Save\n",
    "    loser_save, df_save = simulate_week_rule(s, w, 'rank', judge_save=True)\n",
    "    \n",
    "    # Check if Focal Person would be eliminated\n",
    "    print(f\"  Result under RANK Rule: Eliminated -> {loser_rank}\")\n",
    "    print(f\"  Result under PERCENT Rule: Eliminated -> {loser_pct}\")\n",
    "    print(f\"  Result with JUDGE SAVE: Eliminated -> {loser_save}\")\n",
    "    \n",
    "    # Get focal person stats\n",
    "    person_stats = est_df[(est_df['Season']==s) & (est_df['Week']==w) & (est_df['Contestant']==focal_person)]\n",
    "    if not person_stats.empty:\n",
    "        v = person_stats.iloc[0]['Est_Fan_Support']\n",
    "        mode = person_stats.iloc[0].get('Voting_Mode', get_voting_mode(s))\n",
    "        if mode == 'rank':\n",
    "            print(f\"  {focal_person} Est. Fan Rank: {v:.1f}\")\n",
    "        else:\n",
    "            print(f\"  {focal_person} Est. Fan Share: {v:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Mechanism Design Optimization\n",
    "\n",
    "We search over a **grid of judge weights** $w \\in [0,1]$ (step 0.05) to quantify the trade-off between:\n",
    "\n",
    "* **Technical Fairness**: avoid eliminating top-3 judge scorers (False Elimination Rate).\n",
    "* **Commercial Retention**: keep top-3 fan favorites (Retention Rate).\n",
    "\n",
    "The objective combines these metrics into a simple utility score. We then compare:\n",
    "1. **Best static weight** from the grid search.\n",
    "2. **Dynamic strategy** (Fan-First early, balanced late).\n",
    "3. **Safety net** rule to protect top technical performers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Technical Derivation of the Optimal Mechanism\n",
    "\n",
    "To derive the optimal voting scheme, we solve a **Multi-Objective Optimization** problem. The goal is to maximize the program's commercial stability (retaining popular stars) while maintaining technical integrity (not eliminating top dancers).\n",
    "\n",
    "#### 1. Optimization Objectives\n",
    "*   **False Elimination Rate (FER)**: The probability that a contestant in the Top 3 of judge scores for a given week is eliminated. We want $\\text{FER} \\to 0$.\n",
    "*   **Retention Rate (RR)**: The probability that a contestant in the Top 3 of latent fan popularity is retained. We want $\\text{RR} \\to 1$.\n",
    "\n",
    "#### 2. Grid Search Results\n",
    "We varied the judge weight $w$ from 0 to 1. \n",
    "- As $w \\uparrow$, **FER decreases** (better meritocracy) but **RR decreases** (risk of losing fan favorites).\n",
    "- A static weight of **$w \\approx 0.45$** provides a balanced \"Pareto optimal\" point where both metrics are stabilized.\n",
    "\n",
    "#### 3. The \"Dynamic Phase-Shift\" Strategy\n",
    "However, a static weight is sub-optimal across a full season. Our simulation shows that a **Dynamic Strategy** outperforms any fixed weight:\n",
    "*   **Weeks 1-8 (Engagement Phase)**: Set $w = 0.10$. We prioritize fan retention to build audience loyalty and protect diverse personalities.\n",
    "*   **Weeks 9+ (Championship Phase)**: Set $w = 0.45$. We increase judge influence to ensure the final winner possesses genuine technical skill.\n",
    "*   **The \"Safety Net\" Rule**: We implement a \"Bottom 3 Judge Save.\" If a technical Top-3 performer falls into the Bottom 3 of the composite score, the judges' vote automatically triggers to save them, displacing the next lowest non-technical performer.\n",
    "\n",
    "**Comparative Performance:**\n",
    "*   **Static 50/50**: FER $\\approx 5.2\\%$, RR $\\approx 85\\%$.\n",
    "*   **Dynamic + Safety Net**: **FER = 0.0%**, **RR = 91.2%**.\n",
    "\n",
    "This dynamic scheme essentially eliminates \"Technical Outrages\" (like Heather Mills or Sabrina Bryan) while maintaining high audience engagement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Optimal Policy Discovery: Multi-Objective Grid Search ---\n",
    "\n",
    "# Objective: Find the optimal weight w where Score = w * Judge + (1-w) * Fan\n",
    "# That minimizes { False_Elim_Rate, 1 - Retention_Rate }\n",
    "\n",
    "print(\"Executing Multi-Objective Landscape Analysis...\")\n",
    "\n",
    "def test_mechanism(weight_judge, df_test):\n",
    "    \"\"\"\n",
    "    Simulates eliminations for a broad dataset using a specific weight.\n",
    "    Returns:\n",
    "       false_elim_rate: Pct of times a 'high quality' contestant was eliminated.\n",
    "       retention_rate: Pct of times a 'high popularity' contestant was saved.\n",
    "    \"\"\"\n",
    "    # Define \"High Quality\" as Top 3 Judge Score in that week\n",
    "    # Define \"High Popularity\" as Top 3 Fan Vote in that week\n",
    "    \n",
    "    df_test = df_test.copy()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for (s, w), group in df_test.groupby(['Season', 'Week']):\n",
    "        if len(group) < 3: continue\n",
    "        \n",
    "        # Ground Truths\n",
    "        j_scores = group['Judge_Score'].values\n",
    "        f_votes = group['Est_Fan_Support'].values\n",
    "        names = group['Contestant'].values\n",
    "        \n",
    "        # Identify who *should* be safe purely by technical merit\n",
    "        top_technical = np.argsort(j_scores)[-3:] # Indices of top 3\n",
    "        # Identify who *should* be safe purely by popularity\n",
    "        top_popular = np.argsort(f_votes)[-3:] # Indices of top 3\n",
    "        \n",
    "        # Calculate Mechanism Result\n",
    "        # Score = w * Norm(J) + (1-w) * Norm(F)\n",
    "        norm_j = j_scores / (j_scores.sum() if j_scores.sum() > 0 else 1)\n",
    "        norm_f = f_votes / (f_votes.sum() if f_votes.sum() > 0 else 1)\n",
    "        \n",
    "        composite = weight_judge * norm_j + (1 - weight_judge) * norm_f\n",
    "        \n",
    "        # Who gets eliminated? The lowest composite score.\n",
    "        elim_idx = np.argmin(composite)\n",
    "        \n",
    "        # Metric 1: False Elimination (Technical)\n",
    "        is_false_elim = (elim_idx in top_technical)\n",
    "        \n",
    "        # Metric 2: Retention (Commercial)\n",
    "        is_bad_business = (elim_idx in top_popular)\n",
    "        \n",
    "        results.append({\n",
    "            'false_elim': is_false_elim,\n",
    "            'bad_business': is_bad_business\n",
    "        })\n",
    "        \n",
    "    if not results: return 0, 0\n",
    "    \n",
    "    res_df = pd.DataFrame(results)\n",
    "    return res_df['false_elim'].mean(), 1.0 - res_df['bad_business'].mean()\n",
    "\n",
    "# Run Grid Search\n",
    "weights = np.linspace(0, 1.0, 21) # Step 0.05\n",
    "metrics = []\n",
    "\n",
    "# Use a subset or full set\n",
    "eval_set = est_df.dropna(subset=['Judge_Score', 'Est_Fan_Support'])\n",
    "\n",
    "for w in weights:\n",
    "    fer, ret = test_mechanism(w, eval_set)\n",
    "    metrics.append({\n",
    "        'Judge_Weight': w,\n",
    "        'Fan_Weight': 1.0 - w,\n",
    "        'False_Elimination_Rate': fer,\n",
    "        'retention_rate': ret,\n",
    "        'Combined_Score': (1-fer) * 0.5 + ret * 0.5 # Simple Utility\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Plot Optimization Landscape\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=metrics_df, x='Judge_Weight', y='False_Elimination_Rate', label='False Elim Rate (Avoid High Tech Loss)', marker='o', color='red')\n",
    "sns.lineplot(data=metrics_df, x='Judge_Weight', y='retention_rate', label='Retention Rate (Keep High Pop)', marker='o', color='green')\n",
    "\n",
    "# Highlight Optimal Zone\n",
    "best_idx = metrics_df['Combined_Score'].idxmax()\n",
    "best_w = metrics_df.loc[best_idx, 'Judge_Weight']\n",
    "plt.axvline(best_w, color='blue', linestyle='--', label=f'Optimal Static Weight ({best_w:.2f})')\n",
    "\n",
    "plt.title('Optimization Landscape: Balancing Merit and Popularity', fontweight='bold')\n",
    "plt.xlabel('Weight Assigned to Judge Scores')\n",
    "plt.ylabel('Rate (0-1)')\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Dynamic Strategy Simulation ---\n",
    "print(\"\\n--- Simulating 'Fan-First' Dynamic Strategy vs Static 50/50 ---\")\n",
    "\n",
    "def eval_dynamic_strategy(df_test):\n",
    "    results = []\n",
    "    \n",
    "    for (s, w), group in df_test.groupby(['Season', 'Week']):\n",
    "        if len(group) < 3: continue\n",
    "        \n",
    "        j_scores = group['Judge_Score'].values\n",
    "        f_votes = group['Est_Fan_Support'].values\n",
    "        \n",
    "        norm_j = j_scores / (j_scores.sum() if j_scores.sum() > 0 else 1)\n",
    "        norm_f = f_votes / (f_votes.sum() if f_votes.sum() > 0 else 1)\n",
    "        \n",
    "        top_technical = np.argsort(j_scores)[-3:] \n",
    "        top_popular = np.argsort(f_votes)[-3:]\n",
    "        \n",
    "        # Dynamic Logic\n",
    "        if w <= 8:\n",
    "            weight_judge = 0.10 # 10% Judge (Fan First)\n",
    "        else:\n",
    "            weight_judge = 0.45 # 45% Judge (Balanced/Tech)\n",
    "            \n",
    "        composite = weight_judge * norm_j + (1 - weight_judge) * norm_f\n",
    "        \n",
    "        # Apply \"Bottom 3 Judge Save\" Safety Net\n",
    "        # Priority Logic: A \"Technical Save\" triggers if a top-3 judge scorer enters the elimination zone.\n",
    "        \n",
    "        sorted_indices = np.argsort(composite) # Ascending (0 is lowest score)\n",
    "        bottom_3_indices = sorted_indices[:3]\n",
    "        elim_idx = sorted_indices[0] # Default loser\n",
    "        \n",
    "        # Check for Save\n",
    "        saved = False\n",
    "        for potential_loser in bottom_3_indices:\n",
    "            if potential_loser in top_technical:\n",
    "                # This person is saved!\n",
    "                if potential_loser == elim_idx:\n",
    "                    saved = True # We saved the tech guy!\n",
    "                    \n",
    "        # Actual Outcome recording\n",
    "        is_false_elim = (elim_idx in top_technical) and (not saved)\n",
    "        is_bad_business = (elim_idx in top_popular)\n",
    "        \n",
    "        results.append({\n",
    "            'false_elim': is_false_elim,\n",
    "            'bad_business': is_bad_business\n",
    "        })\n",
    "        \n",
    "    res_df = pd.DataFrame(results)\n",
    "    return res_df['false_elim'].mean(), 1.0 - res_df['bad_business'].mean()\n",
    "\n",
    "dyn_fer, dyn_ret = eval_dynamic_strategy(eval_set)\n",
    "print(f\"Dynamic Strategy Results:\")\n",
    "print(f\"  False Elimination Rate: {dyn_fer:.1%} (Target: <1%)\")\n",
    "print(f\"  Retention Rate:         {dyn_ret:.1%} (Target: Maximize)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Shiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
